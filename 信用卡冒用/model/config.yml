app_config:
    # Overview
    package_name: "model-training"
    
    # Training data
    training_data: "/data/training.csv"

    val_data: "/data/public.csv"

    test_data: '/data/private_1_processed.csv'

    # pipeline_save_file: "logistic_regression_output_v"
    pipeline_save_file: "random_forest_output_v"
    # pipeline_save_file: "xgboost_output_v"
    #pipeline_save_file: "lightgbm_output_v"

    predict_path: "/data/private_1_processed.csv"
    
log_config:
    target: "label"

    used_model: 'random_forest'
    
    samples_to_train_ratio: 1

    # not used features
    to_drop: 
        -
    #     - "flam1"
    #     - "txkey"
    #     - "chid"
    #     - "cano"
    #     - "mchno"
    #     - "acqic"
        
    object_features:
        - "txkey"
        - "chid"
        - "cano"
        - "mchno"
        - "acqic"
    
    numeric_features:
        - "locdt"
        - "loctm"
        - "conam"
        - "iterm"
        - "csmam"
        - "flam1"

    categorical_features:
        - "etymd"
        - "mcc"
        - "ecfg"
        - "scity"
        - "ovrlt"
        - "csmcu"
        - "txkey"
        - "chid"
        - "cano"
        - "mchno"
        - "acqic"
        - "contp"
        - "bnsfg"
        - "stocn"
        - "stscd"
        - "flbmk"
        - "hcefg"
        - "flg_3dsmk"
 
    
    # For train test split
    random_state: 42
    test_size: 0.1

    vars_with_na:
        - "etymd"
        - "mcc"
        - "scity"
        - "csmcu"
        - "stocn"
        - "stscd"
        - "hcefg"

    time_transform: "loctm"

    use_sampling: False
    
    # smote hyperparameters
    smote:
        sampling_strategy: 1
        k_neighbors: 4
        

    # logistic hyperparameters
    logistic:
        max_iter: 5000
        solver: "saga"
        n_jobs: -1

    # random forest hyperparameters
    random_forest:
        n_estimators: 250
        bootstrap: True
        random_state: 42
        class_weight: 
            0: 99.63
            1: 0.37
        n_jobs: -1
    xgb:
        objective: "binary:logistic"
        random_state: 42
        scale_pos_weight: 1
        learning_rate: 0.1
        device: "cuda"
    lgb:
        objective: 'binary'
        random_state: 42
        device: "cpu"
        n_estimators: 500
        n_jobs: -1
        
    precision_recall_threshold: 0.6

    
cv_config:
    stratifiedkfold:
        n_splits: 5
        shuffle: True
        random_state: 42
    random_forest:
        random_forest__criterion: 
            - 'gini'
            - 'entropy'
            - 'log_loss'
        random_forest__n_estimators: 
            - 200
            - 250
            - 300
        random_forest__max_depth: 
            - 
            - 10 
            - 20
        random_forest__min_samples_leaf:
            - 1
            - 2
            - 4
        random_forest__min_samples_split:
            - 2
            - 4
            - 8
        
    
mlflow_config:
    experiment_name: 'lightgbm'

    experiment_tags:
        project_name: 'detect credit card fraud'
        mlflow.note/content: 'This is the experiment for lightbgm'

    artifact_path: 'lightgbm'
    
    run_name: 'train threshold 0.9'
        
        
    

